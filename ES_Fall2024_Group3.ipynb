{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiLY9wsVG5V6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from jetbot import Camera, bgr8_to_jpeg, Robot\n",
        "import traitlets\n",
        "import ipywidgets.widgets as widgets\n",
        "from IPython.display import display\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize the camera with a specific width and height\n",
        "camera = Camera.instance(width=224, height=224)\n",
        "\n",
        "# Create image widgets to display the camera feed and green mask\n",
        "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
        "green_mask_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
        "green_area_widget = widgets.IntText(\n",
        "    value=0,\n",
        "    description='Green Area:',\n",
        "    disabled=True,\n",
        "    layout=widgets.Layout(width='200px')\n",
        ")\n",
        "\n",
        "# Initialize the robot\n",
        "robot = Robot()\n",
        "\n",
        "# Global variables for recovery mechanism and cooldown timer\n",
        "last_direction = None  # Last known direction ('left' or 'right')\n",
        "last_green_detection_time = 0  # Timestamp of the last green detection\n",
        "COOLDOWN_TIME = 3.8   # Cooldown period in seconds\n",
        "\n",
        "\n",
        "def process_image(camera_value, crop_ratio_vertical=0, crop_ratio_horizontal=0):\n",
        "    global last_direction, last_green_detection_time\n",
        "    # Define speeds\n",
        "    MAX_LINEAR_SPEED = -0.11\n",
        "    MIN_LINEAR_SPEED = -0.11\n",
        "    ANGULAR_SPEED = 0.045\n",
        "    STRAFE_SPEED = -0.15\n",
        "    UTURN_SPEED = 0.15\n",
        "    # Get the current time\n",
        "    current_time = time.time()\n",
        "\n",
        "    # Get the dimensions of the original image\n",
        "    height, width, _ = camera_value.shape\n",
        "\n",
        "    # Calculate cropping boundaries based on crop_ratio\n",
        "    crop_top = int(height * crop_ratio_vertical / 2)\n",
        "    crop_bottom = height - crop_top\n",
        "    crop_left = int(width * crop_ratio_horizontal / 2)\n",
        "    crop_right = width - crop_left\n",
        "\n",
        "    # Crop the BGR image based on specified vertical and horizontal ratios\n",
        "    cropped_bgr = camera_value[crop_top:crop_bottom, crop_left:crop_right]\n",
        "\n",
        "    # Enhance the red channel to reduce noise\n",
        "    b, g, r = cv2.split(cropped_bgr)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))  # CLAHE for local contrast enhancement\n",
        "    r_eq = clahe.apply(r)  # Apply CLAHE to the red channel\n",
        "    img_rgb_eq = cv2.merge([b, g, r_eq])\n",
        "\n",
        "    # Convert to HSV for color-based segmentation\n",
        "    hsv = cv2.cvtColor(img_rgb_eq, cv2.COLOR_BGR2HSV)\n",
        "    lower_green = np.array([80, 90, 85])   # Adjusted thresholds for green detection\n",
        "    upper_green = np.array([110, 200, 160])\n",
        "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "    # Apply morphological operations to clean up the green mask\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, kernel)  # Close gaps in the mask\n",
        "    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_OPEN, kernel)   # Remove small noise\n",
        "\n",
        "    # Focus on the middle part of the camera for green area calculation\n",
        "    middle_top = int(height * 0.3)  # Top boundary for middle part\n",
        "    middle_bottom = int(height )  # Bottom boundary for middle part\n",
        "    middle_mask = green_mask[middle_top:middle_bottom, :]  # Extract middle part\n",
        "\n",
        "    # Calculate the area of the green mask in the middle part using contours\n",
        "    TURN_SIZE_THRESHOLD = 160\n",
        "    green_detected = False\n",
        "    green_centers = []\n",
        "\n",
        "    contours, _ = cv2.findContours(middle_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    green_area = 0\n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 100:  # Ignore small noisy regions\n",
        "            green_area += area\n",
        "            M = cv2.moments(contour)\n",
        "            if M['m00'] > 0:\n",
        "#                 green_x = int(M['m10'] / M['m00'])  # X-coordinate of the centroid\n",
        "#                 green_y = int(M['m01'] / M['m00'])  # Y-coordinate of the centroid\n",
        "#                 green_y_array.append((green_y))  # Store as a tuple (X, Y)\n",
        "                green_centers.append(int(M['m10'] / M['m00']))  # Calculate the centroid X position\n",
        "            if green_area >= TURN_SIZE_THRESHOLD:\n",
        "                green_detected = True\n",
        "#                 break;\n",
        "\n",
        "    # Update the green area widget\n",
        "    green_area_widget.value = green_area\n",
        "    print(f\"Green Area in middle part: {green_area}\")\n",
        "\n",
        "    # Red Line Detection Logic\n",
        "    lower_red1 = np.array([0, 120, 70])     # Lower range for red\n",
        "    upper_red1 = np.array([10, 255, 255])  # Upper range for red\n",
        "    lower_red2 = np.array([170, 120, 70])   # Second range for red (hue wrap-around)\n",
        "    upper_red2 = np.array([179, 255, 255])\n",
        "\n",
        "    # Create masks for red regions in both ranges\n",
        "    red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
        "    red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
        "    red_mask = cv2.bitwise_or(red_mask1, red_mask2)  # Combine both red masks\n",
        "\n",
        "    # Focus on the lower 15% of the screen for red detection\n",
        "    lower_red_top = int(height * 0.85)  # Start of the lower 15% region\n",
        "    lower_red_mask = red_mask[lower_red_top:, :]  # Extract the lower 15% part\n",
        "\n",
        "    # Find contours in the red mask\n",
        "    red_detected = False\n",
        "    contours, _ = cv2.findContours(lower_red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours:\n",
        "        area_red = cv2.contourArea(contour)\n",
        "        if area_red > 1000:  # Threshold for significant red regions\n",
        "            red_detected = True\n",
        "            print(\"Red line detected. Stopping the robot.\")\n",
        "            robot.stop()  # Stop the robot\n",
        "            return  # Exit the function\n",
        "\n",
        "\n",
        "        # Line Detection Logic\n",
        "    # Convert the cropped image to grayscale\n",
        "       # Convert the cropped image to grayscale\n",
        "    gray = cv2.cvtColor(cropped_bgr, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian Blur to reduce noise\n",
        "    gray_blurred = cv2.GaussianBlur(gray, (5, 5), 0)  # Kernel size (5, 5) and sigma = 0\n",
        "\n",
        "    # Get the dimensions of the grayscale image\n",
        "    height, width = gray_blurred.shape\n",
        "\n",
        "    # Define central and edge regions\n",
        "    edge_width = 65  # Width of the edge region\n",
        "    center_region = gray_blurred[edge_width:height-edge_width, edge_width:width-edge_width]  # Center part\n",
        "    top_edge = gray_blurred[:edge_width, :]  # Top edge region\n",
        "    bottom_edge = gray_blurred[-edge_width:, :]  # Bottom edge region\n",
        "    left_edge = gray_blurred[:, :edge_width]  # Left edge region\n",
        "    right_edge = gray_blurred[:, -edge_width:]  # Right edge region\n",
        "\n",
        "    # Apply normal processing to the center\n",
        "    _, center_thresh = cv2.threshold(center_region, 100, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Apply black filtering to the edges\n",
        "    lower_black = 0  # Define the lower threshold for black (pure black)\n",
        "    upper_black = 55  # Define the upper threshold for black (adjust as needed)\n",
        "    _, top_thresh = cv2.threshold(top_edge, upper_black, 255, cv2.THRESH_BINARY_INV)\n",
        "    _, bottom_thresh = cv2.threshold(bottom_edge, upper_black, 255, cv2.THRESH_BINARY_INV)\n",
        "    _, left_thresh = cv2.threshold(left_edge, upper_black, 255, cv2.THRESH_BINARY_INV)\n",
        "    _, right_thresh = cv2.threshold(right_edge, upper_black, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Combine the processed regions into a single image\n",
        "    thresh = np.zeros_like(gray_blurred)  # Create a blank image\n",
        "    thresh[edge_width:height-edge_width, edge_width:width-edge_width] = center_thresh  # Fill the center\n",
        "    thresh[:edge_width, :] = top_thresh  # Fill the top edge\n",
        "    thresh[-edge_width:, :] = bottom_thresh  # Fill the bottom edge\n",
        "    thresh[:, :edge_width] = left_thresh  # Fill the left edge\n",
        "    thresh[:, -edge_width:] = right_thresh  # Fill the right edge\n",
        "\n",
        "    # Get the dimensions of the combined binary image\n",
        "    cropped_height, cropped_width = thresh.shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Line following ROI\n",
        "    roi = thresh[int(cropped_height * 0.4):, :]  # Bottom half for line detection\n",
        "    moments = cv2.moments(roi)\n",
        "    line_detected = moments['m00'] > 0\n",
        "    cx = int(moments['m10'] / moments['m00']) if line_detected else cropped_width // 2\n",
        "\n",
        "\n",
        "\n",
        "    # Invalid turn detection and U-turn logic update\n",
        "    if green_detected and current_time - last_green_detection_time > COOLDOWN_TIME:\n",
        "        invalid_turn = False\n",
        "\n",
        "        for center in green_centers:\n",
        "            # Define area around green marker\n",
        "            green_x = int(center)\n",
        "            crop_start_x = max(green_x - 25, 0)\n",
        "            crop_end_x = min(green_x + 25, cropped_width)\n",
        "            crop_start_y = middle_top - 200\n",
        "            crop_end_y = crop_start_y + 400\n",
        "            cropped_area = thresh[crop_start_y:crop_end_y, crop_start_x:crop_end_x]\n",
        "\n",
        "            white_area = np.sum(cropped_area == 255)\n",
        "            total_area = cropped_area.shape[0] * cropped_area.shape[1]\n",
        "            white_percentage = (white_area / total_area) * 100 if total_area > 0 else 0\n",
        "            print(f\"White Percentage: {white_percentage:.2f}%\")\n",
        "\n",
        "            if white_percentage > 45:\n",
        "                print(\"Invalid turn detected near green marker. Skipping turn.\")\n",
        "                last_green_detection_time = current_time\n",
        "                invalid_turn = True\n",
        "                break\n",
        "\n",
        "\n",
        "        left_green = any(center < cx for center in green_centers)  # Green on the left of the line\n",
        "        right_green = any(center > cx for center in green_centers)  # Green on the right of the line\n",
        "        # New behavior: move straight towards the green marker\n",
        "        green_x = np.mean(green_centers)\n",
        "        error = green_x - cropped_width // 2\n",
        "        print(f\"Green detected. Center X: {green_x}, Error: {error}\")\n",
        "\n",
        "#         if abs(error) < 14:\n",
        "#             print(\"Moving straight towards the green marker.\")\n",
        "# #             robot.set_motors(-MIN_LINEAR_SPEED, -MIN_LINEAR_SPEED)\n",
        "#         elif error > 0:\n",
        "#             print(\"Adjusting right to align with the green marker.\")\n",
        "# #             robot.set_motors(-MIN_LINEAR_SPEED + ANGULAR_SPEED, -MIN_LINEAR_SPEED - ANGULAR_SPEED)\n",
        "#         else:\n",
        "#             print(\"Adjusting left to align with the green marker.\")\n",
        "# #             robot.set_motors(-MIN_LINEAR_SPEED - ANGULAR_SPEED, -MIN_LINEAR_SPEED + ANGULAR_SPEED)\n",
        "\n",
        "#         time.sleep(0.3)  # Move straight for 1 second\n",
        "#         robot.stop()\n",
        "#         last_green_detection_time = current_time\n",
        "\n",
        "\n",
        "        # Existing turn logic\n",
        "        if invalid_turn:\n",
        "            last_green_detection_time = current_time\n",
        "            robot.set_motors(-MIN_LINEAR_SPEED, -MIN_LINEAR_SPEED)  # U-turn motion\n",
        "            time.sleep(1)  # Pause for U-turn\n",
        "            robot.stop()\n",
        "            time.sleep(1.7)\n",
        "            robot.stop()\n",
        "\n",
        "\n",
        "        elif left_green and right_green:  # Green detected on both sides of the line\n",
        "            print(\"Green detected on both sides of the line. Performing U-turn.\")\n",
        "            last_green_detection_time = current_time\n",
        "            robot.set_motors(-MIN_LINEAR_SPEED, -MIN_LINEAR_SPEED)  # U-turn motion\n",
        "            time.sleep(1.5)\n",
        "            robot.stop()\n",
        "\n",
        "            robot.set_motors(0.25, -0.25)  # U-turn motion\n",
        "            time.sleep(0.625)  # Pause for U-turn\n",
        "            robot.stop()\n",
        "        elif left_green:  # Green on the left\n",
        "            print(\"Green is to the left of the line. Turning left.\")\n",
        "            last_green_detection_time = current_time\n",
        "            robot.set_motors(-MIN_LINEAR_SPEED, -MIN_LINEAR_SPEED)  # U-turn motion\n",
        "            time.sleep(1.5)\n",
        "            robot.set_motors(-UTURN_SPEED,UTURN_SPEED)  # U-turn motion\n",
        "            time.sleep(0.55)\n",
        "            robot.stop()\n",
        "            time.sleep(1)\n",
        "            robot.stop()\n",
        "\n",
        "        elif right_green:  # Green on the right\n",
        "            print(\"Green is to the left of the line. Turning left.\")\n",
        "            last_green_detection_time = current_time\n",
        "            robot.set_motors(-MIN_LINEAR_SPEED, -MIN_LINEAR_SPEED)  # U-turn motion\n",
        "            time.sleep(1.5)\n",
        "            robot.set_motors(UTURN_SPEED,-UTURN_SPEED)  # U-turn motion\n",
        "            time.sleep(0.55)\n",
        "            robot.stop()\n",
        "            time.sleep(1)\n",
        "            robot.stop()\n",
        "\n",
        "\n",
        "    # Obstacle Detection Logic\n",
        "    obstacle_roi = thresh[:int(cropped_height * 0.5), :]  # Top half for obstacle detection\n",
        "    obstacle_contours, _ = cv2.findContours(obstacle_roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    obstacle_detected = False\n",
        "    for contour in obstacle_contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 4700:  # Threshold for detecting obstacles\n",
        "            obstacle_detected = True\n",
        "            print(\"Obstacle detected!\")\n",
        "            break\n",
        "\n",
        "    # Default behavior if no green or obstacle\n",
        "    if obstacle_detected:\n",
        "        print(\"Stopping due to obstacle!\")\n",
        "        robot.stop()\n",
        "    else:\n",
        "        # Line following logic\n",
        "        if line_detected:\n",
        "            error = cx - cropped_width // 2\n",
        "            print(f\"Line detected. CX: {cx}, Error: {error}\")\n",
        "            if abs(error) < 10:\n",
        "                robot.set_motors(-MIN_LINEAR_SPEED, -MIN_LINEAR_SPEED)\n",
        "            elif error > 0:\n",
        "                last_direction = 'right'\n",
        "                robot.set_motors(-MIN_LINEAR_SPEED + ANGULAR_SPEED, -MIN_LINEAR_SPEED - ANGULAR_SPEED)\n",
        "            else:\n",
        "                last_direction = 'left'\n",
        "                robot.set_motors(-MIN_LINEAR_SPEED - ANGULAR_SPEED, -MIN_LINEAR_SPEED + ANGULAR_SPEED)\n",
        "\n",
        "        else:\n",
        "            robot.set_motors(-MAX_LINEAR_SPEED, -MAX_LINEAR_SPEED)  # Default forward motion\n",
        "\n",
        "    # Update green mask widget with the green mask\n",
        "    green_mask_widget.value = bgr8_to_jpeg(cv2.cvtColor(green_mask, cv2.COLOR_GRAY2BGR))\n",
        "\n",
        "    return bgr8_to_jpeg(cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR))\n",
        "\n",
        "# Link the processed image to the image widget\n",
        "camera_link = traitlets.dlink(\n",
        "    (camera, 'value'),\n",
        "    (image_widget, 'value'),\n",
        "    transform=lambda img: process_image(img, crop_ratio_vertical=0, crop_ratio_horizontal=0)\n",
        ")\n",
        "\n",
        "# Display the widgets in the notebook\n",
        "display(widgets.HBox([image_widget, green_mask_widget, green_area_widget]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sdDGHq3YG7QI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}